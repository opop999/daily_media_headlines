# Automated News API scrape and transformation with GitHub Actions

name: News API extraction

# Controls when the action will run.
on:
  schedule:
    - cron:  '30 5 * * *'
  push:
    branches: main
    
jobs: 
  autoscrape:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest
    container: rocker/tidyverse:latest

    # Load repo and run the scraping script
    steps:
    - uses: actions/checkout@v2
    - name: Extract headlines through API
    # This action needs a NEWS API token as an environment variable (we are using GitHub Secrets)
      env:
          NEWS_API_KEY: ${{ secrets.NEWS_API_KEY }}
      run: Rscript 01_get_news.R
    - name: Install Flexdashboard package
      run: Rscript -e "install.packages('flexdashboard')"
    - name: Update Dashboard for GitHub Pages  
      run: Rscript -e "rmarkdown::render('index.Rmd')"
    - name: Print information about the session
      run: Rscript -e "sessionInfo()"
    
 # Add new files in specified folder, commit along with other modified files, push
    - name: Commit files
      run: |
        git config --local user.name actions-user
        git config --local user.email "actions@github.com"
        git add data/* index.html
        git commit -am "GH Action $(date)"
        git push origin master
      env:
        REPO_KEY: ${{secrets.GITHUB_TOKEN}}
        username: github-actions
